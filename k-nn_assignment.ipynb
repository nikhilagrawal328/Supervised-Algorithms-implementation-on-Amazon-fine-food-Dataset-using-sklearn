{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Amazon Fine Food Reviews Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n",
    "* Number of reviews: 568,454\n",
    "* Number of users: 256,059\n",
    "* Number of products: 74,258\n",
    "* Timespan: Oct 1999 - Oct 2012\n",
    "* Number of Attributes/Columns in data: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "* Id\n",
    "* ProductId - unique identifier for the product\n",
    "* UserId - unqiue identifier for the user\n",
    "* ProfileName\n",
    "* HelpfulnessNumerator - number of users who found the review helpful\n",
    "* HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "* Score - rating between 1 and 5\n",
    "* Time - timestamp for the review\n",
    "* Summary - brief summary of the review\n",
    "* Text - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "Find the right K for all like bow, tf-idf, avg w2v, tf-idf w2v and also report the test accuracy for the chosen K for all the techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\abc\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "import string\n",
    "import sqlite3\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect('F:/Applied AI Course/Amazon fine food review dataset/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con) \n",
    "\n",
    "\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                  ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "138706                     0                       0  positive   939340800   \n",
       "138688                     1                       1  positive  1194739200   \n",
       "138689                     1                       1  positive  1191456000   \n",
       "138690                     1                       1  positive  1076025600   \n",
       "138691                     3                       4  positive  1018396800   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "138690      a good swingy rhythm for reading aloud   \n",
       "138691             A great way to learn the months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  \n",
       "138690  This is a great little book to read aloud- it ...  \n",
       "138691  This is a book of poetry about the months of t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final=final.iloc[:100000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = final.sort_values('Time',axis=0,kind=\"quicksort\", ascending=True,inplace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId               ProfileName  \\\n",
       "0  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "1  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "2  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "3  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "4  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "0                     0                       0  positive  939340800   \n",
       "1                     2                       2  positive  940809600   \n",
       "2                     0                       0  positive  944092800   \n",
       "3                     1                       2  positive  944438400   \n",
       "4                     0                       0  positive  946857600   \n",
       "\n",
       "                                             Summary  \\\n",
       "0                          EVERY book is educational   \n",
       "1  This whole series is great way to spend time w...   \n",
       "2                               Entertainingl Funny!   \n",
       "3                            A modern day fairy tale   \n",
       "4                                         FANTASTIC!   \n",
       "\n",
       "                                                Text  \n",
       "0  this witty little book makes my son laugh at l...  \n",
       "1  I can remember seeing the show when it aired o...  \n",
       "2  Beetlejuice is a well written movie ..... ever...  \n",
       "3  A twist of rumplestiskin captured on film, sta...  \n",
       "4  Beetlejuice is an excellent and funny movie. K...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    85197\n",
       "negative    14803\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasti\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub('[^A-Za-z0-9]+','',sentence)\n",
    "    return  cleaned\n",
    "\n",
    "\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower()):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string\n",
    "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.to_pickle('100k_knn_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final=pd.read_pickle('100k_knn_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final=final.iloc[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = final[\"CleanedText\"]\n",
    "y = final[\"Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        this witti littl book make son laugh loud reci...\n",
      "1        can rememb see the show when air televis year ...\n",
      "2        beetlejuic well written movi everyth about exc...\n",
      "3        twist rumplestiskin captur film star michael k...\n",
      "4        beetlejuic excel and funni movi keaton hilari ...\n",
      "5        this one movi that should your movi collect fi...\n",
      "6        myself alway enjoy this movi it veri funni and...\n",
      "7        bought few these after apart was infest with f...\n",
      "8        what happen when you say his name three time m...\n",
      "9        get crazyim look for beatlejuic french version...\n",
      "10       get crazi realli imposs today not find the fre...\n",
      "11       this was realli good idea and the final produc...\n",
      "12       just receiv shipment and could hard wait tri t...\n",
      "13       have just recent purchas the woodstream corp g...\n",
      "14       this are much easier use than the wilson past ...\n",
      "15       these are easi use they not make mess and offe...\n",
      "16       this such great film dont even know how sum fi...\n",
      "17       beetlejuic aweinspir wonder amus comed romp th...\n",
      "18       sick scad nasti toothpick all over counter whe...\n",
      "19       thought this movi was funni michael keaton bee...\n",
      "20       mani movi have dealt with the figur death and ...\n",
      "21       dont know whi anyon would ever use those littl...\n",
      "22       michael keaton bring distinguish characterist ...\n",
      "23       continu amaz the shoddi treatment that some mo...\n",
      "24       just warn you when tri trick you the widescree...\n",
      "25       bought these decor some dia los muerto skull w...\n",
      "26       winona ryder hot hot hot the gothic deathrock ...\n",
      "27       this was favorit book mine when was littl girl...\n",
      "28       for year have been tri simul truli italian esp...\n",
      "29       when vacat adam and barbara maitland meet thei...\n",
      "                               ...                        \n",
      "49970    this rub super it just great know peopl that d...\n",
      "49971    order this gum for game and the prize guess ho...\n",
      "49972    have purchas the sever time and have never had...\n",
      "49973    best bread gluten free far easi with bread mac...\n",
      "49974    this light breakfast brew not for those who dr...\n",
      "49975    use this when cook shrimp shred chicken taco b...\n",
      "49976    after read anoth review this coffe gave tri no...\n",
      "49977    dont fool the name these are not the real will...\n",
      "49978    same complaint made elsewher this product horr...\n",
      "49979    probabl the best bbq sauc have ever use have t...\n",
      "49980    local purchas organ wheatgrass seed more expen...\n",
      "49981    put all the trap out unfinish basement did cat...\n",
      "49982    was recommend this product pet store employe w...\n",
      "49983    these are simpli the best dark chocol cooki iv...\n",
      "49984    have acid reflux for coupl year doe bother lot...\n",
      "49985    realli enjoy custard but not like make from sc...\n",
      "49986    wasnt sure exact what expect but these are ver...\n",
      "49987    like this stuff becaus tast just like sugar bu...\n",
      "49988    you have time the morn for sit down breakfast ...\n",
      "49989    about order more this twine afternoon tea that...\n",
      "49990    outstand this difficult find product tasti and...\n",
      "49991    have found that this tea has spoil for other b...\n",
      "49992    most peopl love peanut but few brand provid qu...\n",
      "49993    love this bbq sauc husband bbq enthusiast and ...\n",
      "49994    the best peach flavor tea have ever foundthank...\n",
      "49995    bought this rome and just got home and open wo...\n",
      "49996    dont know what go the groceri store but use lo...\n",
      "49997    these are definit the best granola bar ive tas...\n",
      "49998    continu disappoint with the qualiti the camel ...\n",
      "49999    our dog get pumpkin mix with her dri food groc...\n",
      "Name: CleanedText, Length: 50000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "X_1=X[:math.ceil(len(final)*.8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "y_1=y[:math.ceil(len(final)*.8)]\n",
    "X_test=X[math.ceil(len(final)*.8):]\n",
    "y_test=y[math.ceil(len(final)*.8):]\n",
    "\n",
    "print(X_1.shape,y_1.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (30000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_1[:math.ceil(len(final)*.6)]\n",
    "y_train=y_1[:math.ceil(len(final)*.6)]\n",
    "X_CV=X_1[math.ceil(len(final)*.6):]\n",
    "y_CV=y_1[math.ceil(len(final)*.6):]\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_CV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating K using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "X_train = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = count_vect.transform(X_test)\n",
    "X_CV=count_vect.transform(X_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using brute force algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myList = list(range(0,20))\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 83%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 87%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE = [100 - x for x in cv_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 7.\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 7 is 86.670000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array=confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7935c9198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(array, range(2),\n",
    "                  range(2))\n",
    "#plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.63      0.04      0.08      1357\n",
      "   positive       0.87      1.00      0.93      8643\n",
      "\n",
      "avg / total       0.84      0.87      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test ,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix described\n",
    "\n",
    "In above confusion matrix(used to describe performence of classifier)\n",
    "\n",
    "* tn(true negative) = 58, tp(true positive) = 8600, fn(false negative) = 34, fp(false positive) = 1300\n",
    "* And as it is shows in classification report overall accuracy(i.e. how often is the classifier correct?) = (tp+tn)/total = (8600+58)/10000 = ~86.67%\n",
    "* And Overall error rate/misclassification rate or 1-accuracy(i.e. how often it is wrong?) --> (fn+fp)/total = (34+1300)/10000 = ~13.33%\n",
    "* precision --> When it predicts +ve, how often is it correct? = tp/predicted +ve = 8600/9900 = ~86.86%\n",
    "* True Positive rate(tpr)/recall --> When it is actually +ve, how often does it predict +ve? = tp/(real/true/actual +ve) = 8600/8634 = ~99.6%\n",
    "* Specificity(True Negative Rate)--> When it's actually no, how often does it predict no? = tn/actual negative = 58/1357 = ~4.2%. The best specificity is 1.0, whereas the worst is 0.0 .\n",
    "* False Positive rate --> when it is actually -ve, how often does it predicted +ve = fp/actual-ve = 1300/1357 = ~95.7%\n",
    "* F1 score/F-score/F-measure is weighted avg of precision and recall(tpr)=0.928\n",
    "* support is number of elements in each class(+ve and -ve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using kd-tree algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=300)\n",
    "X_train=svd.fit_transform(X_train)\n",
    "X_test=svd.transform(X_test)\n",
    "X_CV=svd.transform(X_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 81%\n",
      "\n",
      "CV accuracy for k = 3 is 85%\n",
      "\n",
      "CV accuracy for k = 5 is 86%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"kd_tree\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE = [1 - x for x in cv_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 15.\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 15 is 86.930000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:\n",
      "0.818305395353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score is:\")\n",
    "print(f1_score(y_test, pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating K using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_1=X[:math.ceil(len(final)*.8)]\n",
    "y_1=y[:math.ceil(len(final)*.8)]\n",
    "X_test=X[math.ceil(len(final)*.8):]\n",
    "y_test=y[math.ceil(len(final)*.8):]\n",
    "\n",
    "print(X_1.shape,y_1.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (30000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_1[:math.ceil(len(final)*.6)]\n",
    "y_train=y_1[:math.ceil(len(final)*.6)]\n",
    "X_CV=X_1[math.ceil(len(final)*.6):]\n",
    "y_CV=y_1[math.ceil(len(final)*.6):]\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_CV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "X_train = tf_idf_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=tf_idf_vect.transform(X_test)\n",
    "X_CV=tf_idf_vect.transform(X_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using brute force algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 85%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 88%\n",
      "\n",
      "CV accuracy for k = 7 is 88%\n",
      "\n",
      "CV accuracy for k = 9 is 88%\n",
      "\n",
      "CV accuracy for k = 11 is 88%\n",
      "\n",
      "CV accuracy for k = 13 is 88%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 7.\n"
     ]
    }
   ],
   "source": [
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 7 is 87.520000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJWSBC6EECr1f1qO5kxcmb4dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7935aff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array=confusion_matrix(y_test, pred)\n",
    "df_cm = pd.DataFrame(array, range(2),\n",
    "                  range(2))\n",
    "#plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.70      0.14      0.24      1357\n",
      "   positive       0.88      0.99      0.93      8643\n",
      "\n",
      "avg / total       0.86      0.88      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test ,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix described\n",
    "\n",
    "In above confusion matrix(used to describe performence of classifier)\n",
    "\n",
    "* tn(true negative) = 190, tp(true positive) = 8600, fn(false negative) = 84, fp(false positive) = 1200\n",
    "* And as it is shows in classification report overall accuracy(i.e. how often is the classifier correct?) = (tp+tn)/total = (8600+190)/10000 = ~87.9%\n",
    "* And Overall error rate/misclassification rate or 1-accuracy(i.e. how often it is wrong?) --> (fn+fp)/total = (84+1200)/10000 = ~12.7%\n",
    "* precision --> When it predicts +ve, how often is it correct? = tp/predicted +ve = 8600/9800 = ~87.7%\n",
    "* True Positive rate(tpr)/recall --> When it is actually +ve, how often does it predict +ve? = tp/(real/true/actual +ve) = 8600/8643 = ~99.6%\n",
    "* Specificity(True Negative Rate)--> When it's actually no, how often does it predict no? = tn/actual negative = 190/1357 = ~14%. The best specificity is 1.0, whereas the worst is 0.0 .\n",
    "* False Positive rate --> when it is actually -ve, how often does it predicted +ve = fp/actual-ve = 1200/1357 = ~88.4%\n",
    "* F1 score/F-score/F-measure is weighted avg of precision and recall(tpr)=0.92\n",
    "* support is number of elements in each class(+ve and -ve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using kd-tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=300)\n",
    "X_train=svd.fit_transform(X_train)\n",
    "X_test=svd.transform(X_test)\n",
    "X_CV=svd.transform(X_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 79%\n",
      "\n",
      "CV accuracy for k = 3 is 83%\n",
      "\n",
      "CV accuracy for k = 5 is 85%\n",
      "\n",
      "CV accuracy for k = 7 is 86%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"kd_tree\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE = [1 - x for x in cv_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 17.\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 17 is 86.700000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:\n",
      "0.815508029567\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score is:\")\n",
    "print(f1_score(y_test, pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating K using w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (30000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "X_1=X[:math.ceil(len(final)*.8)]\n",
    "y_1=y[:math.ceil(len(final)*.8)]\n",
    "X_test=X[math.ceil(len(final)*.8):]\n",
    "y_test=y[math.ceil(len(final)*.8):]\n",
    "\n",
    "X_train=X_1[:math.ceil(len(final)*.6)]\n",
    "y_train=y_1[:math.ceil(len(final)*.6)]\n",
    "X_CV=X_1[math.ceil(len(final)*.6):]\n",
    "y_CV=y_1[math.ceil(len(final)*.6):]\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_CV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own train corpus\n",
    "import gensim\n",
    "\n",
    "\n",
    "list_of_sent=[]\n",
    "    \n",
    "for sent in X_train:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'witti', 'littl', 'book', 'make', 'son', 'laugh', 'loud', 'recit', 'the', 'car', 'were', 'drive', 'along', 'and', 'alway', 'can', 'sing', 'the', 'refrain', 'hes', 'learn', 'about', 'whale', 'india', 'droop', 'rose', 'love', 'all', 'the', 'new', 'word', 'this', 'book', 'introduc', 'and', 'the', 'silli', 'all', 'this', 'classic', 'book', 'will', 'bet', 'son', 'will', 'still', 'abl', 'recit', 'from', 'memori', 'when', 'colleg']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 5 times  7806\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words that occured minimum 5 times \",len(w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words  ['this', 'littl', 'book', 'make', 'son', 'laugh', 'loud', 'the', 'car', 'were', 'drive', 'along', 'and', 'alway', 'can', 'sing', 'hes', 'learn', 'about', 'india', 'rose', 'love', 'all', 'new', 'word', 'introduc', 'silli', 'classic', 'will', 'bet', 'still', 'abl', 'from', 'memori', 'when', 'colleg', 'rememb', 'see', 'show', 'air', 'televis', 'year', 'ago', 'was', 'child', 'sister', 'later', 'bought', 'which', 'have']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample words \", w2v[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30000/30000 [34:17<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "from tqdm import tqdm\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(X_train): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [11:34<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "\n",
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(X_test): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)\n",
    "print(len(sent_vectors_test))\n",
    "print(len(sent_vectors_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [10:53<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "\n",
    "sent_vectors_CV = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in tqdm(X_CV): # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors_CV.append(sent_vec)\n",
    "print(len(sent_vectors_CV))\n",
    "print(len(sent_vectors_CV[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sent_vectors\n",
    "X_test = sent_vectors_test\n",
    "X_CV= sent_vectors_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Performing knn using brute force algorithm for avg w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 87%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 87%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE = [1 - x for x in cv_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 1.\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='brute')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 1 is 13.570000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.14      1.00      0.24      1357\n",
      "   positive       0.00      0.00      0.00      8643\n",
      "\n",
      "avg / total       0.02      0.14      0.03     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test ,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using kd-tree algorithm for avgw2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD()\n",
    "X_train=svd.fit_transform(X_train)\n",
    "X_test=svd.transform(X_test)\n",
    "X_CV=svd.transform(X_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 12%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 87%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"kd_tree\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE = [1 - x for x in cv_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 3.\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 3 is 86.430000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:\n",
      "0.801388714263\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score is:\")\n",
    "print(f1_score(y_test, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,) (30000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_1=X[:math.ceil(len(final)*.8)]\n",
    "y_1=y[:math.ceil(len(final)*.8)]\n",
    "X_test=X[math.ceil(len(final)*.8):]\n",
    "y_test=y[math.ceil(len(final)*.8):]\n",
    "\n",
    "X_train=X_1[:math.ceil(len(final)*.6)]\n",
    "y_train=y_1[:math.ceil(len(final)*.6)]\n",
    "X_CV=X_1[math.ceil(len(final)*.6):]\n",
    "y_CV=y_1[math.ceil(len(final)*.6):]\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_CV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TfidfVectorizer()\n",
    "tf_idf_matrix = model.fit_transform(X_train)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30000/30000 [33:24<00:00, 14.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in tqdm(X_train): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*sent.count(word)\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [11:43<00:00, 14.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in tqdm(X_test): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*sent.count(word)\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_test.append(sent_vec)\n",
    "    row += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [11:17<00:00, 14.75it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_sent_vectors_CV = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in tqdm(X_CV): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*sent.count(word)\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_CV.append(sent_vec)\n",
    "    row += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = tfidf_sent_vectors\n",
    "X_test = tfidf_sent_vectors_test\n",
    "X_CV=tfidf_sent_vectors_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using brute force algorithm for tf-idf w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 87%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 87%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 1.\n"
     ]
    }
   ],
   "source": [
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm = \"brute\")\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 1 is 86.430000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7947e1978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "array=confusion_matrix(y_test, pred)\n",
    "df_cm = pd.DataFrame(array, range(2),\n",
    "                  range(2))\n",
    "#plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.00      0.00      0.00      1357\n",
      "   positive       0.86      1.00      0.93      8643\n",
      "\n",
      "avg / total       0.75      0.86      0.80     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test ,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix described\n",
    "\n",
    "In above confusion matrix(used to describe performence of classifier)\n",
    "\n",
    "* tn(true negative) = 0, tp(true positive) = 8600, fn(false negative) = 0, fp(false positive) = 1400\n",
    "* And as it is shows in classification report overall accuracy(i.e. how often is the classifier correct?) = (tp+tn)/total = (8600+0)/10000 = ~86%\n",
    "* And Overall error rate/misclassification rate or 1-accuracy(i.e. how often it is wrong?) --> (fn+fp)/total = (0+1400)/10000 = ~14%\n",
    "* precision --> When it predicts +ve, how often is it correct? = tp/predicted +ve = 8600/10000 = ~86%\n",
    "* True Positive rate(tpr)/recall --> When it is actually +ve, how often does it predict +ve? = tp/(real/true/actual +ve) = 8600/8643 = ~99.6%\n",
    "* Specificity(True Negative Rate)--> When it's actually no, how often does it predict no? = tn/actual negative = 0/1357 = ~0%. The best specificity is 1.0, whereas the worst is 0.0 .\n",
    "\n",
    "* F1 score/F-score/F-measure is weighted avg of precision and recall(tpr)=0.926\n",
    "* support is number of elements in each class(+ve and -ve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing knn using kd-tree algorithm for tf-idf w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD()\n",
    "X_train=svd.fit_transform(X_train)\n",
    "X_test=svd.transform(X_test)\n",
    "X_CV=svd.transform(X_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for k = 1 is 12%\n",
      "\n",
      "CV accuracy for k = 3 is 87%\n",
      "\n",
      "CV accuracy for k = 5 is 87%\n",
      "\n",
      "CV accuracy for k = 7 is 87%\n",
      "\n",
      "CV accuracy for k = 9 is 87%\n",
      "\n",
      "CV accuracy for k = 11 is 87%\n",
      "\n",
      "CV accuracy for k = 13 is 87%\n",
      "\n",
      "CV accuracy for k = 15 is 87%\n",
      "\n",
      "CV accuracy for k = 17 is 87%\n",
      "\n",
      "CV accuracy for k = 19 is 87%\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"kd_tree\")\n",
    "     # fitting the model on crossvalidation train\n",
    "    knn.fit(X_train, y_train)\n",
    "    # predict the response on the crossvalidation train\n",
    "    pred = knn.predict(X_CV)\n",
    "     # evaluate CV accuracy\n",
    "    acc = accuracy_score(y_CV, pred, normalize=True) * float(100)\n",
    "    cv_scores.append(acc)\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of neighbors is 3.\n"
     ]
    }
   ],
   "source": [
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k,algorithm='kd_tree')\n",
    "\n",
    "# fitting the model\n",
    "knn_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the knn classifier for k = 3 is 86.430000%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:\n",
      "0.801388714263\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score is:\")\n",
    "print(f1_score(y_test, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Vectorization_Technique\", \"Best 'K'\", \"Accuracy on Test Data(%)\", \"Algorithm\",\"F1 Score\"]\n",
    "\n",
    "x.add_row([\"BOW\", 7, 86.670000, 'brute',0.928])\n",
    "x.add_row([\"BOW\", 15, 86.670000, 'kd_tree',0.818])\n",
    "x.add_row([\"tf-idf\", 7, 87.520000, 'brute',0.932])\n",
    "x.add_row([\"tf-idf\", 17, 87.520000, 'kd_tree',0.815])\n",
    "x.add_row([\"Average w2v\", 1, 13.570000, 'brute',0.926])\n",
    "x.add_row([\"Average w2v\", 3, 13.570000, 'kd_tree',0.801])\n",
    "x.add_row([\"tf-idf w2v\", 1, 86.430000, 'brute',0.926])\n",
    "x.add_row([\"tf-idf w2v\", 3, 86.430000, 'kd_tree',0.801])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------+--------------------------+-----------+----------+\n",
      "| Vectorization_Technique | Best 'K' | Accuracy on Test Data(%) | Algorithm | F1 Score |\n",
      "+-------------------------+----------+--------------------------+-----------+----------+\n",
      "|           BOW           |    7     |          86.67           |   brute   |  0.928   |\n",
      "|           BOW           |    15    |          86.67           |  kd_tree  |  0.818   |\n",
      "|          tf-idf         |    7     |          87.52           |   brute   |  0.932   |\n",
      "|          tf-idf         |    17    |          87.52           |  kd_tree  |  0.815   |\n",
      "|       Average w2v       |    1     |          13.57           |   brute   |  0.926   |\n",
      "|       Average w2v       |    3     |          13.57           |  kd_tree  |  0.801   |\n",
      "|        tf-idf w2v       |    1     |          86.43           |   brute   |  0.926   |\n",
      "|        tf-idf w2v       |    3     |          86.43           |  kd_tree  |  0.801   |\n",
      "+-------------------------+----------+--------------------------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we clearly see that for tf-idf accuracy is 87.52 and F1 Score is 0.932(which is maximum). Hence, we conclude that tf-idf vectorization model is good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
